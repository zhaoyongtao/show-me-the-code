## 第 0009 题 提取网页中的超链接

> 我的解法

```
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# 第 0009 题 提取网页中的超链接

#导入request,beautiful模块
from bs4 import BeautifulSoup
import requests
#url地址
url='http://www.ruanyifeng.com/blog/2015/05/co.html'

def findlink(url):
    '''
      提取网页中的超链接
    '''
    #使用beautiful过滤a
    content=requests.get(url).content
    soup=BeautifulSoup(content)
    return soup

if __name__=="__main__":
    soup=findlink(url)
    for link in soup.find_all('a'):
        print(link.get('href'))

```


> 网上的另一个可以参考的解法：

```
#!/usr/bin/env python
# -*- coding: utf-8 -*-
import urllib2
import sys
reload(sys)
sys.setdefaultencoding("utf-8")

# 要分析的网页url
url = 'http://www.ruanyifeng.com/blog/2015/05/co.html'

def findAllLink(url):
    '''
    提取网页中的超链接
    '''
    # 获取协议，域名
    proto, rest = urllib.splittype(url)
    domain = urllib.splithost(rest)[0]
    # 读取网页内容
    html = urllib2.urlopen(url).read()
    # 提取超链接
    a = BeautifulSoup(html).findAll('a')
    # 过滤
    alist = [i.attrs['href'] for i in a if i.attrs['href'][0] != 'j']
    # 将形如#comment-text的锚点补全成http://www.ruanyifeng.com/blog/2015/05/co.html,将形如/feed.html补全为http://www.ruanyifeng.com/feed.html
    alist = map(lambda i: proto + '://' + domain + i if i[0] == '/' else url + i if i[0] == '#' else i, alist)
    return alist

if __name__ == '__main__':
    for i in findAllLink(url):
        print i

```
